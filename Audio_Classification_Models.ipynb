{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "MaTzG-v4O9Wj",
        "outputId": "ae02d264-1181-4fa0-cbe3-4e518f028f2b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting soundata\n",
            "  Downloading soundata-1.0.1-py3-none-any.whl.metadata (7.4 kB)\n",
            "Requirement already satisfied: librosa>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from soundata) (0.11.0)\n",
            "Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.12/dist-packages (from soundata) (2.0.2)\n",
            "Requirement already satisfied: pandas>=1.3.5 in /usr/local/lib/python3.12/dist-packages (from soundata) (2.2.2)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.12/dist-packages (from soundata) (4.67.1)\n",
            "Collecting jams>=0.3.4 (from soundata)\n",
            "  Downloading jams-0.3.5-py3-none-any.whl.metadata (4.5 kB)\n",
            "Collecting py7zr>=0.16.0 (from soundata)\n",
            "  Downloading py7zr-1.0.0-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: jsonschema>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from jams>=0.3.4->soundata) (4.25.1)\n",
            "Collecting mir_eval>=0.8.2 (from jams>=0.3.4->soundata)\n",
            "  Downloading mir_eval-0.8.2-py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: sortedcontainers>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from jams>=0.3.4->soundata) (2.4.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from jams>=0.3.4->soundata) (1.17.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.12/dist-packages (from jams>=0.3.4->soundata) (4.4.2)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.12/dist-packages (from librosa>=0.10.0->soundata) (3.1.0)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.12/dist-packages (from librosa>=0.10.0->soundata) (0.60.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from librosa>=0.10.0->soundata) (1.16.3)\n",
            "Requirement already satisfied: scikit-learn>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from librosa>=0.10.0->soundata) (1.6.1)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.12/dist-packages (from librosa>=0.10.0->soundata) (1.5.2)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.12/dist-packages (from librosa>=0.10.0->soundata) (0.13.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.12/dist-packages (from librosa>=0.10.0->soundata) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.12/dist-packages (from librosa>=0.10.0->soundata) (1.0.0)\n",
            "Requirement already satisfied: typing_extensions>=4.1.1 in /usr/local/lib/python3.12/dist-packages (from librosa>=0.10.0->soundata) (4.15.0)\n",
            "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.12/dist-packages (from librosa>=0.10.0->soundata) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.12/dist-packages (from librosa>=0.10.0->soundata) (1.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.3.5->soundata) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.3.5->soundata) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.3.5->soundata) (2025.2)\n",
            "Collecting texttable (from py7zr>=0.16.0->soundata)\n",
            "  Downloading texttable-1.7.0-py2.py3-none-any.whl.metadata (9.8 kB)\n",
            "Requirement already satisfied: pycryptodomex>=3.20.0 in /usr/local/lib/python3.12/dist-packages (from py7zr>=0.16.0->soundata) (3.23.0)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from py7zr>=0.16.0->soundata) (1.2.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from py7zr>=0.16.0->soundata) (5.9.5)\n",
            "Collecting pyzstd>=0.16.1 (from py7zr>=0.16.0->soundata)\n",
            "  Downloading pyzstd-0.18.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (2.6 kB)\n",
            "Collecting pyppmd<1.3.0,>=1.1.0 (from py7zr>=0.16.0->soundata)\n",
            "  Downloading pyppmd-1.2.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.4 kB)\n",
            "Collecting pybcj<1.1.0,>=1.0.0 (from py7zr>=0.16.0->soundata)\n",
            "  Downloading pybcj-1.0.7-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (3.9 kB)\n",
            "Collecting multivolumefile>=0.2.3 (from py7zr>=0.16.0->soundata)\n",
            "  Downloading multivolumefile-0.2.3-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting inflate64<1.1.0,>=1.0.0 (from py7zr>=0.16.0->soundata)\n",
            "  Downloading inflate64-1.0.4-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.0.1->jams>=0.3.4->soundata) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.0.1->jams>=0.3.4->soundata) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.0.1->jams>=0.3.4->soundata) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.0.1->jams>=0.3.4->soundata) (0.29.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from lazy_loader>=0.1->librosa>=0.10.0->soundata) (25.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba>=0.51.0->librosa>=0.10.0->soundata) (0.43.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from pooch>=1.1->librosa>=0.10.0->soundata) (4.5.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from pooch>=1.1->librosa>=0.10.0->soundata) (2.32.4)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.1.0->librosa>=0.10.0->soundata) (3.6.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.12/dist-packages (from soundfile>=0.12.1->librosa>=0.10.0->soundata) (2.0.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa>=0.10.0->soundata) (2.23)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa>=0.10.0->soundata) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa>=0.10.0->soundata) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa>=0.10.0->soundata) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa>=0.10.0->soundata) (2025.11.12)\n",
            "Downloading soundata-1.0.1-py3-none-any.whl (162 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.0/162.0 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jams-0.3.5-py3-none-any.whl (67 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading py7zr-1.0.0-py3-none-any.whl (69 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.7/69.7 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading inflate64-1.0.4-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (100 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.6/100.6 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mir_eval-0.8.2-py3-none-any.whl (102 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.8/102.8 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multivolumefile-0.2.3-py3-none-any.whl (17 kB)\n",
            "Downloading pybcj-1.0.7-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (51 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.5/51.5 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyppmd-1.2.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (142 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.7/142.7 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyzstd-0.18.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (429 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m429.9/429.9 kB\u001b[0m \u001b[31m41.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading texttable-1.7.0-py2.py3-none-any.whl (10 kB)\n",
            "Installing collected packages: texttable, pyzstd, pyppmd, pybcj, multivolumefile, inflate64, py7zr, mir_eval, jams, soundata\n",
            "Successfully installed inflate64-1.0.4 jams-0.3.5 mir_eval-0.8.2 multivolumefile-0.2.3 py7zr-1.0.0 pybcj-1.0.7 pyppmd-1.2.0 pyzstd-0.18.0 soundata-1.0.1 texttable-1.7.0\n"
          ]
        }
      ],
      "source": [
        "!pip install soundata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "t2Fkhw1rIEX7"
      },
      "outputs": [],
      "source": [
        "# IMPORTS AND SETUP\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import librosa\n",
        "import librosa.display\n",
        "import soundfile as sf\n",
        "from pathlib import Path\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from torch.utils.data import TensorDataset\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "import torchvision.models as models\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import (accuracy_score, precision_recall_fscore_support,\n",
        "                             confusion_matrix, classification_report,\n",
        "                             matthews_corrcoef, roc_curve, auc, roc_auc_score)\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler, label_binarize\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "import os\n",
        "import random\n",
        "import pickle\n",
        "from tqdm import tqdm\n",
        "import soundata\n",
        "from torch.cuda.amp import autocast, GradScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uix8qBVn-OEW",
        "outputId": "e279b816-8ff4-44da-e14e-956737046267"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using Device: cuda\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Set random seeds\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "random.seed(42)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(42)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'Using Device: {device}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "llEuka8b-ZDq"
      },
      "outputs": [],
      "source": [
        "# FEATURE EXTRACTION AND CACHING\n",
        "\n",
        "class FeatureExtractor:\n",
        "    def __init__(self, cache_dir='./feature_cache'):\n",
        "        self.cache_dir = Path(cache_dir)\n",
        "        self.cache_dir.mkdir(exist_ok=True)\n",
        "\n",
        "    def extract_mfcc_features(self, y, sr, n_mfcc=40):\n",
        "        \"\"\"Extract MFCC features and compute statistics\"\"\"\n",
        "        mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
        "        mfcc_delta = librosa.feature.delta(mfcc)\n",
        "        mfcc_delta2 = librosa.feature.delta(mfcc, order=2)\n",
        "\n",
        "        # Compute statistics\n",
        "        features = []\n",
        "        for feat in [mfcc, mfcc_delta, mfcc_delta2]:\n",
        "            features.extend([\n",
        "                np.mean(feat, axis=1),\n",
        "                np.std(feat, axis=1),\n",
        "                np.max(feat, axis=1),\n",
        "                np.min(feat, axis=1)\n",
        "            ])\n",
        "\n",
        "        return np.concatenate(features)\n",
        "\n",
        "    def extract_mel_spectrogram(self, y, sr, n_mels=128):\n",
        "        \"\"\"Extract mel spectrogram for CNN models\"\"\"\n",
        "        mel_spec = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=n_mels,\n",
        "                                                   n_fft=2048, hop_length=512)\n",
        "        mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
        "        mel_spec_db = (mel_spec_db - mel_spec_db.mean()) / (mel_spec_db.std() + 1e-6)\n",
        "        return mel_spec_db\n",
        "\n",
        "    def extract_mfcc_sequence(self, y, sr, n_mfcc=40):\n",
        "        \"\"\"Extract MFCC sequence for 1D CNN\"\"\"\n",
        "        mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
        "        return mfcc\n",
        "\n",
        "    def process_audio(self, audio_path, sr=22050, duration=4):\n",
        "        \"\"\"Load and preprocess audio\"\"\"\n",
        "        y, _ = librosa.load(audio_path, sr=sr, duration=duration)\n",
        "\n",
        "        # Pad or truncate\n",
        "        target_length = sr * duration\n",
        "        if len(y) < target_length:\n",
        "            y = np.pad(y, (0, target_length - len(y)), mode='constant')\n",
        "        else:\n",
        "            y = y[:target_length]\n",
        "\n",
        "        return y, sr\n",
        "\n",
        "    def extract_all_features(self, metadata, soundata_loader, feature_type='mfcc_stats'):\n",
        "        \"\"\"Extract features for all samples with caching\"\"\"\n",
        "        cache_file = self.cache_dir / f'{feature_type}_features.pkl'\n",
        "\n",
        "        if cache_file.exists():\n",
        "            print(f'Loading Cached Features From {cache_file}')\n",
        "            with open(cache_file, 'rb') as f:\n",
        "                return pickle.load(f)\n",
        "\n",
        "        print(f'Extracting {feature_type} Features')\n",
        "        features = []\n",
        "        labels = []\n",
        "\n",
        "        for idx, row in tqdm(metadata.iterrows(), total=len(metadata)):\n",
        "            clip = soundata_loader.clip(row['slice_file_name'])\n",
        "            y, sr = clip.audio\n",
        "\n",
        "            # Ensure consistent length\n",
        "            target_length = sr * 4\n",
        "            if len(y) < target_length:\n",
        "                y = np.pad(y, (0, target_length - len(y)), mode='constant')\n",
        "            else:\n",
        "                y = y[:target_length]\n",
        "\n",
        "            if feature_type == 'mfcc_stats':\n",
        "                feat = self.extract_mfcc_features(y, sr)\n",
        "            elif feature_type == 'mel_spectrogram':\n",
        "                feat = self.extract_mel_spectrogram(y, sr)\n",
        "            elif feature_type == 'mfcc_sequence':\n",
        "                feat = self.extract_mfcc_sequence(y, sr)\n",
        "\n",
        "            features.append(feat)\n",
        "            labels.append(row['class'])\n",
        "\n",
        "        result = {'features': features, 'labels': labels}\n",
        "\n",
        "        # Cache the features\n",
        "        with open(cache_file, 'wb') as f:\n",
        "            pickle.dump(result, f)\n",
        "\n",
        "        print(f'Features Cached To {cache_file}')\n",
        "        return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "zX3Ns-3k-Vmz"
      },
      "outputs": [],
      "source": [
        "# DATASET CLASSES\n",
        "\n",
        "class UrbanSoundMelDataset(Dataset):\n",
        "    \"\"\"Dataset for 2D CNN (Mel Spectrograms)\"\"\"\n",
        "    def __init__(self, metadata, soundata_loader, augment=False):\n",
        "        self.metadata = metadata.reset_index(drop=True)\n",
        "        self.soundata_loader = soundata_loader\n",
        "        self.augment = augment\n",
        "        self.label_encoder = LabelEncoder()\n",
        "        self.labels = self.label_encoder.fit_transform(self.metadata['class'])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.metadata)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.metadata.iloc[idx]\n",
        "        clip = self.soundata_loader.clip(row['slice_file_name'])\n",
        "        y, sr = clip.audio\n",
        "\n",
        "        # Apply augmentations\n",
        "        if self.augment:\n",
        "            if random.random() > 0.5:\n",
        "                y = librosa.effects.pitch_shift(y, sr=sr, n_steps=random.randint(-3, 3))\n",
        "            if random.random() > 0.5:\n",
        "                y = librosa.effects.time_stretch(y, rate=random.uniform(0.8, 1.2))\n",
        "            if random.random() > 0.5:\n",
        "                noise = np.random.randn(len(y))\n",
        "                y = y + random.uniform(0.001, 0.005) * noise\n",
        "\n",
        "        # Pad or truncate\n",
        "        target_length = sr * 4\n",
        "        if len(y) < target_length:\n",
        "            y = np.pad(y, (0, target_length - len(y)), mode='constant')\n",
        "        else:\n",
        "            y = y[:target_length]\n",
        "\n",
        "        # Extract mel spectrogram\n",
        "        mel_spec = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128,\n",
        "                                                   n_fft=2048, hop_length=512)\n",
        "        mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
        "        mel_spec_db = (mel_spec_db - mel_spec_db.mean()) / (mel_spec_db.std() + 1e-6)\n",
        "\n",
        "        mel_spec_tensor = torch.FloatTensor(mel_spec_db).unsqueeze(0)\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        return mel_spec_tensor, label\n",
        "\n",
        "\n",
        "class UrbanSoundMFCCDataset(Dataset):\n",
        "    \"\"\"Dataset for 1D CNN (MFCC Sequences)\"\"\"\n",
        "    def __init__(self, metadata, soundata_loader, augment=False, n_mfcc=40):\n",
        "        self.metadata = metadata.reset_index(drop=True)\n",
        "        self.soundata_loader = soundata_loader\n",
        "        self.augment = augment\n",
        "        self.n_mfcc = n_mfcc\n",
        "        self.label_encoder = LabelEncoder()\n",
        "        self.labels = self.label_encoder.fit_transform(self.metadata['class'])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.metadata)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.metadata.iloc[idx]\n",
        "        clip = self.soundata_loader.clip(row['slice_file_name'])\n",
        "        y, sr = clip.audio\n",
        "\n",
        "        # Apply augmentations\n",
        "        if self.augment:\n",
        "            if random.random() > 0.5:\n",
        "                y = librosa.effects.pitch_shift(y, sr=sr, n_steps=random.randint(-3, 3))\n",
        "            if random.random() > 0.5:\n",
        "                y = librosa.effects.time_stretch(y, rate=random.uniform(0.8, 1.2))\n",
        "\n",
        "        # Pad or truncate\n",
        "        target_length = sr * 4\n",
        "        if len(y) < target_length:\n",
        "            y = np.pad(y, (0, target_length - len(y)), mode='constant')\n",
        "        else:\n",
        "            y = y[:target_length]\n",
        "\n",
        "        # Extract MFCC\n",
        "        mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=self.n_mfcc)\n",
        "        mfcc_tensor = torch.FloatTensor(mfcc)\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        return mfcc_tensor, label\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qSmjIbn8-qKh"
      },
      "outputs": [],
      "source": [
        "\n",
        "# MODEL CLASSES\n",
        "\n",
        "class RandomForestModel:\n",
        "    def __init__(self, random_state=42):\n",
        "        self.model = None\n",
        "        self.scaler = StandardScaler()\n",
        "        self.random_state = random_state\n",
        "        self.best_params = None\n",
        "\n",
        "    def train(self, X_train, y_train, hyperparameter_tuning=True, best_params=None):\n",
        "        \"\"\"Train Random Forest with optional hyperparameter tuning\"\"\"\n",
        "        print('Training Random Forest Model')\n",
        "\n",
        "        # Scale features\n",
        "        X_train_scaled = self.scaler.fit_transform(X_train)\n",
        "\n",
        "        if hyperparameter_tuning:\n",
        "            print('Performing Grid Search For Hyperparameter Optimization')\n",
        "            param_grid = {\n",
        "                'n_estimators': [100, 200, 300],\n",
        "                'max_depth': [10, 20, 30, None],\n",
        "                'min_samples_split': [2, 5, 10],\n",
        "                'min_samples_leaf': [1, 2, 4]\n",
        "            }\n",
        "\n",
        "            rf = RandomForestClassifier(random_state=self.random_state, n_jobs=-1)\n",
        "            grid_search = GridSearchCV(rf, param_grid, cv=3, scoring='accuracy',\n",
        "                                      n_jobs=-1, verbose=2)\n",
        "            grid_search.fit(X_train_scaled, y_train)\n",
        "\n",
        "            self.model = grid_search.best_estimator_\n",
        "            self.best_params = grid_search.best_params_\n",
        "            print(f'Best Parameters: {self.best_params}')\n",
        "        else:\n",
        "            # Use provided best params or defaults\n",
        "            if best_params is not None:\n",
        "                self.model = RandomForestClassifier(random_state=self.random_state,\n",
        "                                                  n_jobs=-1, **best_params)\n",
        "            else:\n",
        "                self.model = RandomForestClassifier(n_estimators=200, random_state=self.random_state,\n",
        "                                                  n_jobs=-1)\n",
        "            self.model.fit(X_train_scaled, y_train)\n",
        "\n",
        "        print('Random Forest Training Complete')\n",
        "\n",
        "    def predict(self, X_test):\n",
        "        X_test_scaled = self.scaler.transform(X_test)\n",
        "        return self.model.predict(X_test_scaled)\n",
        "\n",
        "    def predict_proba(self, X_test):\n",
        "        X_test_scaled = self.scaler.transform(X_test)\n",
        "        return self.model.predict_proba(X_test_scaled)\n",
        "\n",
        "\n",
        "class SVCModel:\n",
        "    def __init__(self, random_state=42):\n",
        "        self.model = None\n",
        "        self.scaler = StandardScaler()\n",
        "        self.random_state = random_state\n",
        "        self.best_params = None\n",
        "\n",
        "    def train(self, X_train, y_train, hyperparameter_tuning=True, best_params=None):  # ADD best_params=None\n",
        "        \"\"\"Train SVC with optional hyperparameter tuning\"\"\"\n",
        "        print('Training SVC Model')\n",
        "\n",
        "        # Scale features\n",
        "        X_train_scaled = self.scaler.fit_transform(X_train)\n",
        "\n",
        "        if hyperparameter_tuning:\n",
        "            print('Performing Grid Search For Hyperparameter Optimization')\n",
        "            param_grid = {\n",
        "                'C': [0.1, 1, 10, 100],\n",
        "                'gamma': ['scale', 'auto', 0.001, 0.01],\n",
        "                'kernel': ['rbf', 'poly']\n",
        "            }\n",
        "\n",
        "            svc = SVC(random_state=self.random_state, probability=True)\n",
        "            grid_search = GridSearchCV(svc, param_grid, cv=3, scoring='accuracy',\n",
        "                                      n_jobs=-1, verbose=2)\n",
        "            grid_search.fit(X_train_scaled, y_train)\n",
        "\n",
        "            self.model = grid_search.best_estimator_\n",
        "            self.best_params = grid_search.best_params_\n",
        "            print(f'Best Parameters: {self.best_params}')\n",
        "        else:\n",
        "            if best_params is not None:\n",
        "                self.model = SVC(random_state=self.random_state, probability=True, **best_params)\n",
        "            else:\n",
        "                self.model = SVC(kernel='rbf', random_state=self.random_state, probability=True)\n",
        "            self.model.fit(X_train_scaled, y_train)\n",
        "\n",
        "        print('SVC Training Complete')\n",
        "    def predict(self, X_test):\n",
        "        X_test_scaled = self.scaler.transform(X_test)\n",
        "        return self.model.predict(X_test_scaled)\n",
        "\n",
        "    def predict_proba(self, X_test):\n",
        "        X_test_scaled = self.scaler.transform(X_test)\n",
        "        return self.model.predict_proba(X_test_scaled)\n",
        "\n",
        "\n",
        "class KNNModel:\n",
        "    def __init__(self):\n",
        "        self.model = None\n",
        "        self.scaler = StandardScaler()\n",
        "        self.best_params = None\n",
        "\n",
        "    def train(self, X_train, y_train, hyperparameter_tuning=True, best_params=None):  # ADD best_params=None\n",
        "        \"\"\"Train KNN with optional hyperparameter tuning\"\"\"\n",
        "        print('Training KNN Model')\n",
        "\n",
        "        # Scale features\n",
        "        X_train_scaled = self.scaler.fit_transform(X_train)\n",
        "\n",
        "        if hyperparameter_tuning:\n",
        "            print('Performing Grid Search For Hyperparameter Optimization')\n",
        "            param_grid = {\n",
        "                'n_neighbors': [3, 5, 7, 9, 11],\n",
        "                'weights': ['uniform', 'distance'],\n",
        "                'metric': ['euclidean', 'manhattan', 'minkowski']\n",
        "            }\n",
        "\n",
        "            knn = KNeighborsClassifier(n_jobs=-1)\n",
        "            grid_search = GridSearchCV(knn, param_grid, cv=3, scoring='accuracy',\n",
        "                                      n_jobs=-1, verbose=2)\n",
        "            grid_search.fit(X_train_scaled, y_train)\n",
        "\n",
        "            self.model = grid_search.best_estimator_\n",
        "            self.best_params = grid_search.best_params_\n",
        "            print(f'Best Parameters: {self.best_params}')\n",
        "        else:\n",
        "            if best_params is not None:\n",
        "                self.model = KNeighborsClassifier(n_jobs=-1, **best_params)\n",
        "            else:\n",
        "                self.model = KNeighborsClassifier(n_neighbors=5, n_jobs=-1)\n",
        "            self.model.fit(X_train_scaled, y_train)\n",
        "\n",
        "        print('KNN Training Complete')\n",
        "\n",
        "    def predict(self, X_test):\n",
        "        X_test_scaled = self.scaler.transform(X_test)\n",
        "        return self.model.predict(X_test_scaled)\n",
        "\n",
        "    def predict_proba(self, X_test):\n",
        "        X_test_scaled = self.scaler.transform(X_test)\n",
        "        return self.model.predict_proba(X_test_scaled)\n",
        "\n",
        "\n",
        "class ANNModel(nn.Module):\n",
        "    def __init__(self, input_dim, num_classes=10, hidden_dims=[512, 256, 128]):\n",
        "        super(ANNModel, self).__init__()\n",
        "\n",
        "        layers = []\n",
        "        prev_dim = input_dim\n",
        "\n",
        "        for hidden_dim in hidden_dims:\n",
        "            layers.extend([\n",
        "                nn.Linear(prev_dim, hidden_dim),\n",
        "                nn.BatchNorm1d(hidden_dim),\n",
        "                nn.ReLU(),\n",
        "                nn.Dropout(0.3)\n",
        "            ])\n",
        "            prev_dim = hidden_dim\n",
        "\n",
        "        layers.append(nn.Linear(prev_dim, num_classes))\n",
        "        self.network = nn.Sequential(*layers)\n",
        "        self.scaler = StandardScaler()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.network(x)\n",
        "\n",
        "    def train_model(self, X_train, y_train, X_val=None, y_val=None,\n",
        "                   epochs=50, batch_size=64, lr=0.001):\n",
        "        \"\"\"Train ANN model\"\"\"\n",
        "        print('Training ANN Model')\n",
        "\n",
        "        # Scale features\n",
        "        X_train_scaled = self.scaler.fit_transform(X_train)\n",
        "\n",
        "        # Convert to tensors\n",
        "        X_train_tensor = torch.FloatTensor(X_train_scaled).to(device)\n",
        "        y_train_tensor = torch.LongTensor(y_train).to(device)\n",
        "\n",
        "        train_dataset = torch.utils.data.TensorDataset(X_train_tensor, y_train_tensor)\n",
        "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "        self.to(device)\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        optimizer = optim.Adam(self.parameters(), lr=lr)\n",
        "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min',\n",
        "                                                         factor=0.5, patience=5)\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            self.train()\n",
        "            total_loss = 0\n",
        "\n",
        "            for batch_X, batch_y in train_loader:\n",
        "                optimizer.zero_grad()\n",
        "                outputs = self(batch_X)\n",
        "                loss = criterion(outputs, batch_y)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                total_loss += loss.item()\n",
        "\n",
        "            avg_loss = total_loss / len(train_loader)\n",
        "            scheduler.step(avg_loss)\n",
        "\n",
        "            if (epoch + 1) % 10 == 0:\n",
        "                print(f'Epoch [{epoch+1}/{epochs}], Loss: {avg_loss:.4f}')\n",
        "\n",
        "        print('ANN Training Complete')\n",
        "\n",
        "    def predict(self, X_test):\n",
        "        self.eval()\n",
        "        X_test_scaled = self.scaler.transform(X_test)\n",
        "        X_test_tensor = torch.FloatTensor(X_test_scaled).to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = self(X_test_tensor)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "        return predicted.cpu().numpy()\n",
        "\n",
        "    def predict_proba(self, X_test):\n",
        "        self.eval()\n",
        "        X_test_scaled = self.scaler.transform(X_test)\n",
        "        X_test_tensor = torch.FloatTensor(X_test_scaled).to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = self(X_test_tensor)\n",
        "            probs = F.softmax(outputs, dim=1)\n",
        "\n",
        "        return probs.cpu().numpy()\n",
        "\n",
        "\n",
        "class CNN2DModel(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(CNN2DModel, self).__init__()\n",
        "\n",
        "        self.conv_layers = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Dropout(0.25),\n",
        "\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Dropout(0.25),\n",
        "\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Dropout(0.25),\n",
        "\n",
        "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.AdaptiveAvgPool2d((4, 4)),\n",
        "            nn.Dropout(0.25)\n",
        "        )\n",
        "\n",
        "        self.fc_layers = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(256 * 4 * 4, 512),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(512, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv_layers(x)\n",
        "        x = self.fc_layers(x)\n",
        "        return x\n",
        "\n",
        "    def train_model(self, train_loader, val_loader=None, epochs=50, lr=0.001):\n",
        "        \"\"\"Train 2D CNN model\"\"\"\n",
        "        print('Training 2D CNN Model')\n",
        "\n",
        "        self.to(device)\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        optimizer = optim.Adam(self.parameters(), lr=lr)\n",
        "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min',\n",
        "                                                         factor=0.5, patience=5)\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            self.train()\n",
        "            total_loss = 0\n",
        "\n",
        "            for batch_X, batch_y in train_loader:\n",
        "                batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "                outputs = self(batch_X)\n",
        "                loss = criterion(outputs, batch_y)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                total_loss += loss.item()\n",
        "\n",
        "            avg_loss = total_loss / len(train_loader)\n",
        "            scheduler.step(avg_loss)\n",
        "\n",
        "            if (epoch + 1) % 10 == 0:\n",
        "                print(f'Epoch [{epoch+1}/{epochs}], Loss: {avg_loss:.4f}')\n",
        "\n",
        "        print('2D CNN Training Complete')\n",
        "\n",
        "    def predict(self, test_loader):\n",
        "        self.eval()\n",
        "        predictions = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch_X, _ in test_loader:\n",
        "                batch_X = batch_X.to(device)\n",
        "                outputs = self(batch_X)\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                predictions.extend(predicted.cpu().numpy())\n",
        "\n",
        "        return np.array(predictions)\n",
        "\n",
        "    def predict_proba(self, test_loader):\n",
        "        self.eval()\n",
        "        probabilities = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch_X, _ in test_loader:\n",
        "                batch_X = batch_X.to(device)\n",
        "                outputs = self(batch_X)\n",
        "                probs = F.softmax(outputs, dim=1)\n",
        "                probabilities.extend(probs.cpu().numpy())\n",
        "\n",
        "        return np.array(probabilities)\n",
        "\n",
        "\n",
        "class CNN1DModel(nn.Module):\n",
        "    def __init__(self, input_channels=40, num_classes=10):\n",
        "        super(CNN1DModel, self).__init__()\n",
        "\n",
        "        self.conv_layers = nn.Sequential(\n",
        "            nn.Conv1d(input_channels, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm1d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(2),\n",
        "            nn.Dropout(0.25),\n",
        "\n",
        "            nn.Conv1d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(2),\n",
        "            nn.Dropout(0.25),\n",
        "\n",
        "            nn.Conv1d(128, 256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.AdaptiveAvgPool1d(4),\n",
        "            nn.Dropout(0.25)\n",
        "        )\n",
        "\n",
        "        self.fc_layers = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(256 * 4, 256),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(256, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv_layers(x)\n",
        "        x = self.fc_layers(x)\n",
        "        return x\n",
        "\n",
        "    def train_model(self, train_loader, val_loader=None, epochs=50, lr=0.001):\n",
        "        \"\"\"Train 1D CNN model\"\"\"\n",
        "        print('Training 1D CNN Model')\n",
        "\n",
        "        self.to(device)\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        optimizer = optim.Adam(self.parameters(), lr=lr)\n",
        "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min',\n",
        "                                                         factor=0.5, patience=5)\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            self.train()\n",
        "            total_loss = 0\n",
        "\n",
        "            for batch_X, batch_y in train_loader:\n",
        "                batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "                outputs = self(batch_X)\n",
        "                loss = criterion(outputs, batch_y)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                total_loss += loss.item()\n",
        "\n",
        "            avg_loss = total_loss / len(train_loader)\n",
        "            scheduler.step(avg_loss)\n",
        "\n",
        "            if (epoch + 1) % 10 == 0:\n",
        "                print(f'Epoch [{epoch+1}/{epochs}], Loss: {avg_loss:.4f}')\n",
        "\n",
        "        print('1D CNN Training Complete')\n",
        "\n",
        "    def predict(self, test_loader):\n",
        "        self.eval()\n",
        "        predictions = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch_X, _ in test_loader:\n",
        "                batch_X = batch_X.to(device)\n",
        "                outputs = self(batch_X)\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                predictions.extend(predicted.cpu().numpy())\n",
        "\n",
        "        return np.array(predictions)\n",
        "\n",
        "    def predict_proba(self, test_loader):\n",
        "        self.eval()\n",
        "        probabilities = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch_X, _ in test_loader:\n",
        "                batch_X = batch_X.to(device)\n",
        "                outputs = self(batch_X)\n",
        "                probs = F.softmax(outputs, dim=1)\n",
        "                probabilities.extend(probs.cpu().numpy())\n",
        "\n",
        "        return np.array(probabilities)\n",
        "\n",
        "\n",
        "from torchvision.models import efficientnet_b0\n",
        "\n",
        "class AudioEfficientNet(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(AudioEfficientNet, self).__init__()\n",
        "\n",
        "        # 1. Load Pre-trained EfficientNet-B0\n",
        "        self.base_model = efficientnet_b0(weights='DEFAULT')\n",
        "\n",
        "        # 2. Modify Input Layer (1 Channel instead of 3)\n",
        "        # EfficientNet's first layer is in .features[0][0]\n",
        "        original_first_layer = self.base_model.features[0][0]\n",
        "\n",
        "        self.base_model.features[0][0] = nn.Conv2d(\n",
        "            in_channels=1,\n",
        "            out_channels=original_first_layer.out_channels,\n",
        "            kernel_size=original_first_layer.kernel_size,\n",
        "            stride=original_first_layer.stride,\n",
        "            padding=original_first_layer.padding,\n",
        "            bias=False\n",
        "        )\n",
        "\n",
        "        # 3. Modify Classifier (Output)\n",
        "        # EfficientNet's classifier is .classifier[1]\n",
        "        in_features = self.base_model.classifier[1].in_features\n",
        "        self.base_model.classifier[1] = nn.Sequential(\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(in_features, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.base_model(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "v_7eT00b-1WR"
      },
      "outputs": [],
      "source": [
        "\n",
        "# EVALUATION MODULE\n",
        "\n",
        "class ModelEvaluator:\n",
        "    def __init__(self, class_names):\n",
        "        self.class_names = class_names\n",
        "\n",
        "    def compute_metrics(self, y_true, y_pred, y_proba=None):\n",
        "        \"\"\"Compute all evaluation metrics\"\"\"\n",
        "        metrics = {}\n",
        "\n",
        "        # Basic metrics\n",
        "        metrics['accuracy'] = accuracy_score(y_true, y_pred)\n",
        "        precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred,\n",
        "                                                                    average='weighted',\n",
        "                                                                    zero_division=0)\n",
        "        metrics['precision'] = precision\n",
        "        metrics['recall'] = recall\n",
        "        metrics['f1_score'] = f1\n",
        "\n",
        "        # Matthews Correlation Coefficient\n",
        "        metrics['mcc'] = matthews_corrcoef(y_true, y_pred)\n",
        "\n",
        "        # Confusion Matrix\n",
        "        metrics['confusion_matrix'] = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "        # Per-class metrics\n",
        "        class_report = classification_report(y_true, y_pred,\n",
        "                                            target_names=self.class_names,\n",
        "                                            output_dict=True, zero_division=0)\n",
        "        metrics['classification_report'] = class_report\n",
        "\n",
        "        # ROC AUC (if probabilities available)\n",
        "        if y_proba is not None:\n",
        "            try:\n",
        "                y_true_bin = label_binarize(y_true, classes=range(len(self.class_names)))\n",
        "                metrics['roc_auc'] = roc_auc_score(y_true_bin, y_proba,\n",
        "                                                   average='weighted', multi_class='ovr')\n",
        "            except:\n",
        "                metrics['roc_auc'] = None\n",
        "\n",
        "        return metrics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "gigKGShC-8BB"
      },
      "outputs": [],
      "source": [
        "\n",
        "    def print_metrics(self, metrics, model_name):\n",
        "        \"\"\"Print metrics in clean format\"\"\"\n",
        "        print(f'\\nResults For {model_name}')\n",
        "        print(f\"Accuracy: {metrics['accuracy']:.4f}\")\n",
        "        print(f\"Precision: {metrics['precision']:.4f}\")\n",
        "        print(f\"Recall: {metrics['recall']:.4f}\")\n",
        "        print(f\"F1 Score: {metrics['f1_score']:.4f}\")\n",
        "        print(f\"MCC: {metrics['mcc']:.4f}\")\n",
        "        if metrics.get('roc_auc') is not None:\n",
        "            print(f\"ROC AUC: {metrics['roc_auc']:.4f}\")\n",
        "\n",
        "    def plot_confusion_matrix(self, cm, model_name, fold=None):\n",
        "        \"\"\"Plot confusion matrix heatmap\"\"\"\n",
        "        plt.figure(figsize=(10, 8))\n",
        "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                   xticklabels=self.class_names, yticklabels=self.class_names)\n",
        "        title = f'Confusion Matrix - {model_name}'\n",
        "        if fold is not None:\n",
        "            title += f' (Fold {fold})'\n",
        "        plt.title(title)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    def plot_roc_curves(self, y_true, y_proba, model_name, fold=None):\n",
        "        \"\"\"Plot ROC curves for multi-class classification\"\"\"\n",
        "        y_true_bin = label_binarize(y_true, classes=range(len(self.class_names)))\n",
        "\n",
        "        plt.figure(figsize=(12, 8))\n",
        "\n",
        "        for i in range(len(self.class_names)):\n",
        "            fpr, tpr, _ = roc_curve(y_true_bin[:, i], y_proba[:, i])\n",
        "            roc_auc = auc(fpr, tpr)\n",
        "            plt.plot(fpr, tpr, label=f'{self.class_names[i]} (AUC = {roc_auc:.2f})')\n",
        "\n",
        "        plt.plot([0, 1], [0, 1], 'k--', label='Random Classifier')\n",
        "        plt.xlabel('False Positive Rate')\n",
        "        plt.ylabel('True Positive Rate')\n",
        "        title = f'ROC Curves - {model_name}'\n",
        "        if fold is not None:\n",
        "            title += f' (Fold {fold})'\n",
        "        plt.title(title)\n",
        "        plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JjGTgDCq_SJK"
      },
      "outputs": [],
      "source": [
        "\n",
        "# CROSS-VALIDATION PIPELINE\n",
        "\n",
        "def cross_validate_traditional_ml(model_class, metadata, feature_extractor,\n",
        "                                 soundata_loader, model_name,\n",
        "                                 hyperparameter_tuning=True):\n",
        "    \"\"\"10-fold cross-validation for traditional ML models\"\"\"\n",
        "    print(f'\\nStarting 10 Fold Cross Validation For {model_name}')\n",
        "\n",
        "    # Extract features\n",
        "    feature_data = feature_extractor.extract_all_features(metadata, soundata_loader,\n",
        "                                                         feature_type='mfcc_stats')\n",
        "\n",
        "    # Prepare data\n",
        "    X = np.array(feature_data['features'])\n",
        "    label_encoder = LabelEncoder()\n",
        "    y = label_encoder.fit_transform(feature_data['labels'])\n",
        "    class_names = label_encoder.classes_\n",
        "\n",
        "    evaluator = ModelEvaluator(class_names)\n",
        "    fold_metrics = []\n",
        "    best_params = None  \n",
        "\n",
        "    # Iterate through 10 folds\n",
        "    for fold in range(1, 11):\n",
        "        print(f'\\nTraining On Fold {fold}')\n",
        "\n",
        "        # Split data\n",
        "        test_mask = metadata['fold'] == fold\n",
        "        train_mask = ~test_mask\n",
        "\n",
        "        X_train = X[train_mask]\n",
        "        y_train = y[train_mask]\n",
        "        X_test = X[test_mask]\n",
        "        y_test = y[test_mask]\n",
        "\n",
        "        # Train model\n",
        "        model = model_class()\n",
        "\n",
        "        # Only tune hyperparameters on first fold\n",
        "        if fold == 1 and hyperparameter_tuning:\n",
        "            print('Tuning Hyperparameters On First Fold')\n",
        "            model.train(X_train, y_train, hyperparameter_tuning=True)\n",
        "            best_params = model.best_params\n",
        "            print(f'Best Parameters Will Be Used For Remaining Folds: {best_params}')\n",
        "        else:\n",
        "            # Use best params from first fold or defaults\n",
        "            if best_params is not None:\n",
        "                print(f'Using Best Parameters From Fold 1: {best_params}')\n",
        "                model.train(X_train, y_train, hyperparameter_tuning=False, best_params=best_params)\n",
        "            else:\n",
        "                model.train(X_train, y_train, hyperparameter_tuning=False)\n",
        "\n",
        "        # Predict\n",
        "        y_pred = model.predict(X_test)\n",
        "        y_proba = model.predict_proba(X_test)\n",
        "\n",
        "        # Evaluate\n",
        "        metrics = evaluator.compute_metrics(y_test, y_pred, y_proba)\n",
        "        fold_metrics.append(metrics)\n",
        "\n",
        "        print(f\"Fold {fold} Accuracy: {metrics['accuracy']:.4f}\")\n",
        "\n",
        "    # Aggregate results\n",
        "    avg_metrics = aggregate_metrics(fold_metrics)\n",
        "    print(f'\\nAverage Results Across 10 Folds For {model_name}')\n",
        "    print_average_metrics(avg_metrics)\n",
        "\n",
        "    return fold_metrics, avg_metrics\n",
        "\n",
        "\n",
        "def cross_validate_ann(metadata, feature_extractor, soundata_loader,\n",
        "                       model_name='ANN', epochs=50):\n",
        "    \"\"\"10-fold cross-validation for ANN\"\"\"\n",
        "    print(f'\\nStarting 10 Fold Cross Validation For {model_name}')\n",
        "\n",
        "    # Extract features\n",
        "    feature_data = feature_extractor.extract_all_features(metadata, soundata_loader,\n",
        "                                                         feature_type='mfcc_stats')\n",
        "\n",
        "    # Prepare data\n",
        "    X = np.array(feature_data['features'])\n",
        "    label_encoder = LabelEncoder()\n",
        "    y = label_encoder.fit_transform(feature_data['labels'])\n",
        "    class_names = label_encoder.classes_\n",
        "\n",
        "    evaluator = ModelEvaluator(class_names)\n",
        "    fold_metrics = []\n",
        "\n",
        "    # Iterate through 10 folds\n",
        "    for fold in range(1, 11):\n",
        "        print(f'\\nTraining On Fold {fold}')\n",
        "\n",
        "        # Split data\n",
        "        test_mask = metadata['fold'] == fold\n",
        "        train_mask = ~test_mask\n",
        "\n",
        "        X_train = X[train_mask]\n",
        "        y_train = y[train_mask]\n",
        "        X_test = X[test_mask]\n",
        "        y_test = y[test_mask]\n",
        "\n",
        "        # Train model\n",
        "        model = ANNModel(input_dim=X_train.shape[1], num_classes=len(class_names))\n",
        "        model.train_model(X_train, y_train, epochs=epochs)\n",
        "\n",
        "        # Predict\n",
        "        y_pred = model.predict(X_test)\n",
        "        y_proba = model.predict_proba(X_test)\n",
        "\n",
        "        # Evaluate\n",
        "        metrics = evaluator.compute_metrics(y_test, y_pred, y_proba)\n",
        "        fold_metrics.append(metrics)\n",
        "\n",
        "        print(f\"Fold {fold} Accuracy: {metrics['accuracy']:.4f}\")\n",
        "\n",
        "    # Aggregate results\n",
        "    avg_metrics = aggregate_metrics(fold_metrics)\n",
        "    print(f'\\nAverage Results Across 10 Folds For {model_name}')\n",
        "    print_average_metrics(avg_metrics)\n",
        "\n",
        "    return fold_metrics, avg_metrics\n",
        "\n",
        "\n",
        "def cross_validate_cnn2d(metadata, X_all, y_all, model_name='2D CNN', epochs=50, batch_size=32):\n",
        "    print(f'\\nStarting Fast Cross Validation For {model_name}')\n",
        "\n",
        "    # Setup for Mixed Precision (Faster on Colab Pro GPUs)\n",
        "    scaler = GradScaler()\n",
        "\n",
        "    # Get Class Names for metrics\n",
        "    label_encoder = LabelEncoder()\n",
        "    label_encoder.fit(metadata['class'])\n",
        "    class_names = label_encoder.classes_\n",
        "    evaluator = ModelEvaluator(class_names)\n",
        "\n",
        "    fold_metrics = []\n",
        "\n",
        "    for fold in range(1, 11):\n",
        "        print(f'\\nTraining On Fold {fold} (Fast Mode)')\n",
        "\n",
        "        # 1. Get Indices for this fold\n",
        "        train_indices = metadata[metadata['fold'] != fold].index.to_numpy()\n",
        "        test_indices = metadata[metadata['fold'] == fold].index.to_numpy()\n",
        "\n",
        "        # 2. Create Fast Loaders\n",
        "        train_loader = get_fast_dataloader(X_all, y_all, train_indices, batch_size, shuffle=True, is_2d=True)\n",
        "        test_loader = get_fast_dataloader(X_all, y_all, test_indices, batch_size, shuffle=False, is_2d=True)\n",
        "\n",
        "        # 3. Initialize Model\n",
        "        model = CNN2DModel(num_classes=len(class_names)).to(device)\n",
        "        optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "        # 4. Fast Training Loop\n",
        "        model.train()\n",
        "        for epoch in range(epochs):\n",
        "            for batch_X, batch_y in train_loader:\n",
        "                batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # Mixed Precision context\n",
        "                with autocast():\n",
        "                    outputs = model(batch_X)\n",
        "                    loss = criterion(outputs, batch_y)\n",
        "\n",
        "                scaler.scale(loss).backward()\n",
        "                scaler.step(optimizer)\n",
        "                scaler.update()\n",
        "\n",
        "        # 5. Predict & Evaluate\n",
        "        model.eval()\n",
        "        y_pred = []\n",
        "        y_proba = []\n",
        "        y_test_labels = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch_X, batch_y in test_loader:\n",
        "                batch_X = batch_X.to(device)\n",
        "                outputs = model(batch_X)\n",
        "\n",
        "                # Get preds\n",
        "                probs = F.softmax(outputs, dim=1)\n",
        "                predicted = torch.max(probs, 1)[1]\n",
        "\n",
        "                y_pred.extend(predicted.cpu().numpy())\n",
        "                y_proba.extend(probs.cpu().numpy())\n",
        "                y_test_labels.extend(batch_y.numpy())\n",
        "\n",
        "        # Compute Metrics\n",
        "        metrics = evaluator.compute_metrics(np.array(y_test_labels), np.array(y_pred), np.array(y_proba))\n",
        "        fold_metrics.append(metrics)\n",
        "        print(f\"Fold {fold} Accuracy: {metrics['accuracy']:.4f}\")\n",
        "\n",
        "    avg_metrics = aggregate_metrics(fold_metrics)\n",
        "    print(f'\\nAverage Results Across 10 Folds For {model_name}')\n",
        "    print_average_metrics(avg_metrics)\n",
        "    return fold_metrics, avg_metrics\n",
        "\n",
        "\n",
        "def cross_validate_cnn1d(metadata, X_all, y_all, model_name='1D CNN', epochs=50, batch_size=32):\n",
        "    print(f'\\nStarting Fast Cross Validation For {model_name}')\n",
        "    scaler = GradScaler()\n",
        "\n",
        "    label_encoder = LabelEncoder()\n",
        "    label_encoder.fit(metadata['class'])\n",
        "    class_names = label_encoder.classes_\n",
        "    evaluator = ModelEvaluator(class_names)\n",
        "\n",
        "    fold_metrics = []\n",
        "\n",
        "    for fold in range(1, 11):\n",
        "        print(f'\\nTraining On Fold {fold} (Fast Mode)')\n",
        "\n",
        "        train_indices = metadata[metadata['fold'] != fold].index.to_numpy()\n",
        "        test_indices = metadata[metadata['fold'] == fold].index.to_numpy()\n",
        "\n",
        "        train_loader = get_fast_dataloader(X_all, y_all, train_indices, batch_size, shuffle=True, is_2d=False)\n",
        "        test_loader = get_fast_dataloader(X_all, y_all, test_indices, batch_size, shuffle=False, is_2d=False)\n",
        "\n",
        "        model = CNN1DModel(input_channels=40, num_classes=len(class_names)).to(device)\n",
        "        optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "        model.train()\n",
        "        for epoch in range(epochs):\n",
        "            for batch_X, batch_y in train_loader:\n",
        "                batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
        "                optimizer.zero_grad()\n",
        "                with autocast():\n",
        "                    outputs = model(batch_X)\n",
        "                    loss = criterion(outputs, batch_y)\n",
        "                scaler.scale(loss).backward()\n",
        "                scaler.step(optimizer)\n",
        "                scaler.update()\n",
        "\n",
        "        model.eval()\n",
        "        y_pred = []\n",
        "        y_proba = []\n",
        "        y_test_labels = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch_X, batch_y in test_loader:\n",
        "                batch_X = batch_X.to(device)\n",
        "                outputs = model(batch_X)\n",
        "                probs = F.softmax(outputs, dim=1)\n",
        "                predicted = torch.max(probs, 1)[1]\n",
        "\n",
        "                y_pred.extend(predicted.cpu().numpy())\n",
        "                y_proba.extend(probs.cpu().numpy())\n",
        "                y_test_labels.extend(batch_y.numpy())\n",
        "\n",
        "        metrics = evaluator.compute_metrics(np.array(y_test_labels), np.array(y_pred), np.array(y_proba))\n",
        "        fold_metrics.append(metrics)\n",
        "        print(f\"Fold {fold} Accuracy: {metrics['accuracy']:.4f}\")\n",
        "\n",
        "    avg_metrics = aggregate_metrics(fold_metrics)\n",
        "    print(f'\\nAverage Results Across 10 Folds For {model_name}')\n",
        "    print_average_metrics(avg_metrics)\n",
        "    return fold_metrics, avg_metrics\n",
        "\n",
        "\n",
        "def aggregate_metrics(fold_metrics):\n",
        "    \"\"\"Aggregate metrics across folds\"\"\"\n",
        "    metrics_to_avg = ['accuracy', 'precision', 'recall', 'f1_score', 'mcc', 'roc_auc']\n",
        "\n",
        "    avg_metrics = {}\n",
        "    for metric in metrics_to_avg:\n",
        "        values = [fm[metric] for fm in fold_metrics if fm.get(metric) is not None]\n",
        "        if values:\n",
        "            avg_metrics[f'{metric}_mean'] = np.mean(values)\n",
        "            avg_metrics[f'{metric}_std'] = np.std(values)\n",
        "\n",
        "    # Average confusion matrix\n",
        "    cms = [fm['confusion_matrix'] for fm in fold_metrics]\n",
        "    avg_metrics['confusion_matrix'] = np.mean(cms, axis=0).astype(int)\n",
        "\n",
        "    return avg_metrics\n",
        "\n",
        "\n",
        "def print_average_metrics(avg_metrics):\n",
        "    \"\"\"Print averaged metrics\"\"\"\n",
        "    metrics_names = {\n",
        "        'accuracy': 'Accuracy',\n",
        "        'precision': 'Precision',\n",
        "        'recall': 'Recall',\n",
        "        'f1_score': 'F1 Score',\n",
        "        'mcc': 'MCC',\n",
        "        'roc_auc': 'ROC AUC'\n",
        "    }\n",
        "\n",
        "    for metric_key, metric_name in metrics_names.items():\n",
        "        mean_key = f'{metric_key}_mean'\n",
        "        std_key = f'{metric_key}_std'\n",
        "        if mean_key in avg_metrics:\n",
        "            print(f'{metric_name}: {avg_metrics[mean_key]:.4f} (+/- {avg_metrics[std_key]:.4f})')\n",
        "\n",
        "\n",
        "def cross_validate_efficientnet(metadata, X_gpu, y_gpu, model_name='EfficientNet-B0', epochs=15, batch_size=64):\n",
        "    print(f'\\nStarting High-Performance Run for {model_name}')\n",
        "\n",
        "    label_encoder = LabelEncoder()\n",
        "    label_encoder.fit(metadata['class'])\n",
        "    class_names = label_encoder.classes_\n",
        "    evaluator = ModelEvaluator(class_names)\n",
        "    scaler = GradScaler()\n",
        "    fold_metrics = []\n",
        "\n",
        "    for fold in range(1, 11):\n",
        "        print(f'Fold {fold}...', end=' ')\n",
        "\n",
        "        # 1. Slice Data\n",
        "        train_idx = torch.tensor(metadata[metadata['fold'] != fold].index.values).to(device)\n",
        "        test_idx = torch.tensor(metadata[metadata['fold'] == fold].index.values).to(device)\n",
        "\n",
        "        X_train, y_train = X_gpu[train_idx], y_gpu[train_idx]\n",
        "        X_test, y_test = X_gpu[test_idx], y_gpu[test_idx]\n",
        "\n",
        "        # 2. Initialize Model\n",
        "        model = AudioEfficientNet(num_classes=len(class_names)).to(device)\n",
        "\n",
        "        # 3. Optimizer \n",
        "        # We use 1e-4 because we are UNFREEZING the backbone.\n",
        "        # High LR (1e-3) would destroy the pre-trained knowledge.\n",
        "        optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "        # 4. Train Loop (Manual Batching)\n",
        "        model.train()\n",
        "        num_samples = X_train.shape[0]\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            perm = torch.randperm(num_samples, device=device)\n",
        "            for i in range(0, num_samples, batch_size):\n",
        "                indices = perm[i : i + batch_size]\n",
        "                batch_X = X_train[indices]\n",
        "                batch_y = y_train[indices]\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "                with autocast():\n",
        "                    outputs = model(batch_X)\n",
        "                    loss = criterion(outputs, batch_y)\n",
        "\n",
        "                scaler.scale(loss).backward()\n",
        "                scaler.step(optimizer)\n",
        "                scaler.update()\n",
        "\n",
        "        # 5. Eval Loop\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            y_pred = []\n",
        "            y_proba = []\n",
        "            for i in range(0, X_test.shape[0], batch_size):\n",
        "                batch_X = X_test[i : i + batch_size]\n",
        "                outputs = model(batch_X)\n",
        "                probs = F.softmax(outputs, dim=1)\n",
        "                preds = torch.max(probs, 1)[1]\n",
        "                y_pred.extend(preds.cpu().numpy())\n",
        "                y_proba.extend(probs.cpu().numpy())\n",
        "\n",
        "            y_test_cpu = y_test.cpu().numpy()\n",
        "\n",
        "        metrics = evaluator.compute_metrics(np.array(y_test_cpu), np.array(y_pred), np.array(y_proba))\n",
        "        fold_metrics.append(metrics)\n",
        "        print(f\"Acc: {metrics['accuracy']:.4f}\")\n",
        "\n",
        "    avg_metrics = aggregate_metrics(fold_metrics)\n",
        "    print_average_metrics(avg_metrics)\n",
        "    return fold_metrics, avg_metrics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mR7iW3Ua_Wqy",
        "outputId": "88101803-ce41-4a7b-e0e9-4e986b689a0a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initializing UrbanSound8K Dataset\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 640.35it/s]\n",
            "100%|██████████| 8732/8732 [00:16<00:00, 537.05it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset Validated Successfully\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# MAIN EXECUTION\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Initialize dataset\n",
        "    print('Initializing UrbanSound8K Dataset')\n",
        "    urbansound8k = soundata.initialize('urbansound8k')\n",
        "\n",
        "    # Check if dataset exists, if not download\n",
        "    if not os.path.exists(urbansound8k.data_home):\n",
        "        print('Downloading Dataset')\n",
        "        urbansound8k.download()\n",
        "\n",
        "    urbansound8k.validate()\n",
        "    print('Dataset Validated Successfully')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P_3Hc6a7ieX1",
        "outputId": "fcb34bac-c7d3-4e85-8bbd-0769d045924c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset Shape: (8732, 3)\n",
            "Number Of Classes: 10\n"
          ]
        }
      ],
      "source": [
        "    # Load metadata\n",
        "    clip_ids = urbansound8k.clip_ids\n",
        "    metadata_list = []\n",
        "    for clip_id in clip_ids:\n",
        "        clip = urbansound8k.clip(clip_id)\n",
        "        metadata_list.append({\n",
        "            'slice_file_name': clip_id,\n",
        "            'fold': clip.fold,\n",
        "            'class': clip.tags.labels[0] if clip.tags.labels else 'unknown',\n",
        "        })\n",
        "\n",
        "    metadata = pd.DataFrame(metadata_list)\n",
        "    print(f'Dataset Shape: {metadata.shape}')\n",
        "    print(f'Number Of Classes: {metadata[\"class\"].nunique()}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "SDSHb2WziwQM"
      },
      "outputs": [],
      "source": [
        "    # Initialize feature extractor\n",
        "    feature_extractor = FeatureExtractor(cache_dir='./feature_cache')\n",
        "\n",
        "    # Train and evaluate each model\n",
        "    results = {}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_UxOzF9q876b",
        "outputId": "eda9d57a-e31f-4bf4-ea8f-98b640f013a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1. Pre-computing Mel Spectrograms (for 2D CNN)\n",
            "Extracting mel_spectrogram Features\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 8732/8732 [03:40<00:00, 39.57it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Features Cached To feature_cache/mel_spectrogram_features.pkl\n",
            "Mel Spectrogram Shape: (8732, 128, 345)\n",
            "\n",
            "2. Pre-computing MFCC Sequences (for 1D CNN)\n",
            "Extracting mfcc_sequence Features\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 8732/8732 [03:29<00:00, 41.62it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Features Cached To feature_cache/mfcc_sequence_features.pkl\n",
            "MFCC Sequence Shape: (8732, 40, 345)\n"
          ]
        }
      ],
      "source": [
        "print(\"1. Pre-computing Mel Spectrograms (for 2D CNN)\")\n",
        "# Extract Mel Spectrograms for the whole dataset at once\n",
        "mel_data = feature_extractor.extract_all_features(\n",
        "    metadata,\n",
        "    urbansound8k,\n",
        "    feature_type='mel_spectrogram'\n",
        ")\n",
        "# Convert to numpy array\n",
        "X_mel = np.array([x for x in mel_data['features']])\n",
        "y_mel = np.array(mel_data['labels'])\n",
        "print(f\"Mel Spectrogram Shape: {X_mel.shape}\")\n",
        "\n",
        "print(\"\\n2. Pre-computing MFCC Sequences (for 1D CNN)\")\n",
        "# Extract MFCC Sequences for the whole dataset at once\n",
        "mfcc_data = feature_extractor.extract_all_features(\n",
        "    metadata,\n",
        "    urbansound8k,\n",
        "    feature_type='mfcc_sequence'\n",
        ")\n",
        "# Convert to numpy array\n",
        "X_mfcc = np.array([x for x in mfcc_data['features']])\n",
        "y_mfcc = np.array(mfcc_data['labels'])\n",
        "print(f\"MFCC Sequence Shape: {X_mfcc.shape}\")\n",
        "\n",
        "# Helper to create fast DataLoaders from RAM\n",
        "def get_fast_dataloader(X_data, y_data, fold_indices, batch_size=32, shuffle=True, is_2d=False):\n",
        "    # Select data for this fold\n",
        "    X_fold = X_data[fold_indices]\n",
        "    y_fold = y_data[fold_indices]\n",
        "\n",
        "    # Convert to Tensor\n",
        "    tensor_x = torch.FloatTensor(X_fold)\n",
        "\n",
        "    # If 2D CNN, we need to add the \"Channel\" dimension (Batch, 1, Freq, Time)\n",
        "    if is_2d:\n",
        "        tensor_x = tensor_x.unsqueeze(1)\n",
        "\n",
        "    # Encode Labels\n",
        "    le = LabelEncoder()\n",
        "    tensor_y = torch.LongTensor(le.fit_transform(y_fold))\n",
        "\n",
        "    # Create Dataset in RAM\n",
        "    dataset = TensorDataset(tensor_x, tensor_y)\n",
        "\n",
        "    return DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, num_workers=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wVU5zmgDoWdy",
        "outputId": "b7bcf043-9c54-403f-a4b0-38437093a641"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MODEL 1: RANDOM FOREST\n",
            "\n",
            "Starting 10 Fold Cross Validation For Random Forest\n",
            "Loading Cached Features From feature_cache/mfcc_stats_features.pkl\n",
            "\n",
            "Training On Fold 1\n",
            "Tuning Hyperparameters On First Fold\n",
            "Training Random Forest Model\n",
            "Performing Grid Search For Hyperparameter Optimization\n",
            "Fitting 3 folds for each of 108 candidates, totalling 324 fits\n",
            "Best Parameters: {'max_depth': 30, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 300}\n",
            "Random Forest Training Complete\n",
            "Best Parameters Will Be Used For Remaining Folds: {'max_depth': 30, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 300}\n",
            "Fold 1 Accuracy: 0.6644\n",
            "\n",
            "Training On Fold 2\n",
            "Using Best Parameters From Fold 1: {'max_depth': 30, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 300}\n",
            "Training Random Forest Model\n",
            "Random Forest Training Complete\n",
            "Fold 2 Accuracy: 0.6802\n",
            "\n",
            "Training On Fold 3\n",
            "Using Best Parameters From Fold 1: {'max_depth': 30, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 300}\n",
            "Training Random Forest Model\n",
            "Random Forest Training Complete\n",
            "Fold 3 Accuracy: 0.6270\n",
            "\n",
            "Training On Fold 4\n",
            "Using Best Parameters From Fold 1: {'max_depth': 30, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 300}\n",
            "Training Random Forest Model\n",
            "Random Forest Training Complete\n",
            "Fold 4 Accuracy: 0.6778\n",
            "\n",
            "Training On Fold 5\n",
            "Using Best Parameters From Fold 1: {'max_depth': 30, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 300}\n",
            "Training Random Forest Model\n",
            "Random Forest Training Complete\n",
            "Fold 5 Accuracy: 0.6816\n",
            "\n",
            "Training On Fold 6\n",
            "Using Best Parameters From Fold 1: {'max_depth': 30, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 300}\n",
            "Training Random Forest Model\n",
            "Random Forest Training Complete\n",
            "Fold 6 Accuracy: 0.6574\n",
            "\n",
            "Training On Fold 7\n",
            "Using Best Parameters From Fold 1: {'max_depth': 30, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 300}\n",
            "Training Random Forest Model\n",
            "Random Forest Training Complete\n",
            "Fold 7 Accuracy: 0.6802\n",
            "\n",
            "Training On Fold 8\n",
            "Using Best Parameters From Fold 1: {'max_depth': 30, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 300}\n",
            "Training Random Forest Model\n",
            "Random Forest Training Complete\n",
            "Fold 8 Accuracy: 0.6079\n",
            "\n",
            "Training On Fold 9\n",
            "Using Best Parameters From Fold 1: {'max_depth': 30, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 300}\n",
            "Training Random Forest Model\n",
            "Random Forest Training Complete\n",
            "Fold 9 Accuracy: 0.7574\n",
            "\n",
            "Training On Fold 10\n",
            "Using Best Parameters From Fold 1: {'max_depth': 30, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 300}\n",
            "Training Random Forest Model\n",
            "Random Forest Training Complete\n",
            "Fold 10 Accuracy: 0.7515\n",
            "\n",
            "Average Results Across 10 Folds For Random Forest\n",
            "Accuracy: 0.6785 (+/- 0.0445)\n",
            "Precision: 0.6926 (+/- 0.0427)\n",
            "Recall: 0.6785 (+/- 0.0445)\n",
            "F1 Score: 0.6700 (+/- 0.0419)\n",
            "MCC: 0.6425 (+/- 0.0502)\n",
            "ROC AUC: 0.9375 (+/- 0.0166)\n"
          ]
        }
      ],
      "source": [
        "    # 1. Random Forest\n",
        "    print('MODEL 1: RANDOM FOREST')\n",
        "    rf_fold_metrics, rf_avg_metrics = cross_validate_traditional_ml(\n",
        "        RandomForestModel, metadata, feature_extractor, urbansound8k,\n",
        "        model_name='Random Forest', hyperparameter_tuning=True\n",
        "    )\n",
        "    results['Random Forest'] = {'fold_metrics': rf_fold_metrics, 'avg_metrics': rf_avg_metrics}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5-ELN48ooX-L",
        "outputId": "ca954c7c-26da-4735-a46d-1eeca862fb21"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MODEL 2: SVC\n",
            "\n",
            "Starting 10 Fold Cross Validation For SVC\n",
            "Loading Cached Features From feature_cache/mfcc_stats_features.pkl\n",
            "\n",
            "Training On Fold 1\n",
            "Tuning Hyperparameters On First Fold\n",
            "Training SVC Model\n",
            "Performing Grid Search For Hyperparameter Optimization\n",
            "Fitting 3 folds for each of 32 candidates, totalling 96 fits\n",
            "Best Parameters: {'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}\n",
            "SVC Training Complete\n",
            "Best Parameters Will Be Used For Remaining Folds: {'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}\n",
            "Fold 1 Accuracy: 0.6449\n",
            "\n",
            "Training On Fold 2\n",
            "Using Best Parameters From Fold 1: {'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}\n",
            "Training SVC Model\n",
            "SVC Training Complete\n",
            "Fold 2 Accuracy: 0.6610\n",
            "\n",
            "Training On Fold 3\n",
            "Using Best Parameters From Fold 1: {'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}\n",
            "Training SVC Model\n",
            "SVC Training Complete\n",
            "Fold 3 Accuracy: 0.6530\n",
            "\n",
            "Training On Fold 4\n",
            "Using Best Parameters From Fold 1: {'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}\n",
            "Training SVC Model\n",
            "SVC Training Complete\n",
            "Fold 4 Accuracy: 0.6818\n",
            "\n",
            "Training On Fold 5\n",
            "Using Best Parameters From Fold 1: {'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}\n",
            "Training SVC Model\n",
            "SVC Training Complete\n",
            "Fold 5 Accuracy: 0.7714\n",
            "\n",
            "Training On Fold 6\n",
            "Using Best Parameters From Fold 1: {'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}\n",
            "Training SVC Model\n",
            "SVC Training Complete\n",
            "Fold 6 Accuracy: 0.6780\n",
            "\n",
            "Training On Fold 7\n",
            "Using Best Parameters From Fold 1: {'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}\n",
            "Training SVC Model\n",
            "SVC Training Complete\n",
            "Fold 7 Accuracy: 0.6945\n",
            "\n",
            "Training On Fold 8\n",
            "Using Best Parameters From Fold 1: {'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}\n",
            "Training SVC Model\n",
            "SVC Training Complete\n",
            "Fold 8 Accuracy: 0.7047\n",
            "\n",
            "Training On Fold 9\n",
            "Using Best Parameters From Fold 1: {'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}\n",
            "Training SVC Model\n",
            "SVC Training Complete\n",
            "Fold 9 Accuracy: 0.7304\n",
            "\n",
            "Training On Fold 10\n",
            "Using Best Parameters From Fold 1: {'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}\n",
            "Training SVC Model\n",
            "SVC Training Complete\n",
            "Fold 10 Accuracy: 0.7395\n",
            "\n",
            "Average Results Across 10 Folds For SVC\n",
            "Accuracy: 0.6959 (+/- 0.0388)\n",
            "Precision: 0.6965 (+/- 0.0428)\n",
            "Recall: 0.6959 (+/- 0.0388)\n",
            "F1 Score: 0.6864 (+/- 0.0441)\n",
            "MCC: 0.6612 (+/- 0.0429)\n",
            "ROC AUC: 0.9412 (+/- 0.0137)\n"
          ]
        }
      ],
      "source": [
        "    # 2. SVC\n",
        "    print('MODEL 2: SVC')\n",
        "    svc_fold_metrics, svc_avg_metrics = cross_validate_traditional_ml(\n",
        "        SVCModel, metadata, feature_extractor, urbansound8k,\n",
        "        model_name='SVC', hyperparameter_tuning=True\n",
        "    )\n",
        "    results['SVC'] = {'fold_metrics': svc_fold_metrics, 'avg_metrics': svc_avg_metrics}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BlRG9h1Ooddp",
        "outputId": "dc7a1691-1d9c-4b26-f945-309b33dfd327"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MODEL 3: KNN\n",
            "\n",
            "Starting 10 Fold Cross Validation For KNN\n",
            "Loading Cached Features From feature_cache/mfcc_stats_features.pkl\n",
            "\n",
            "Training On Fold 1\n",
            "Tuning Hyperparameters On First Fold\n",
            "Training KNN Model\n",
            "Performing Grid Search For Hyperparameter Optimization\n",
            "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n",
            "Best Parameters: {'metric': 'manhattan', 'n_neighbors': 3, 'weights': 'distance'}\n",
            "KNN Training Complete\n",
            "Best Parameters Will Be Used For Remaining Folds: {'metric': 'manhattan', 'n_neighbors': 3, 'weights': 'distance'}\n",
            "Fold 1 Accuracy: 0.5452\n",
            "\n",
            "Training On Fold 2\n",
            "Using Best Parameters From Fold 1: {'metric': 'manhattan', 'n_neighbors': 3, 'weights': 'distance'}\n",
            "Training KNN Model\n",
            "KNN Training Complete\n",
            "Fold 2 Accuracy: 0.5811\n",
            "\n",
            "Training On Fold 3\n",
            "Using Best Parameters From Fold 1: {'metric': 'manhattan', 'n_neighbors': 3, 'weights': 'distance'}\n",
            "Training KNN Model\n",
            "KNN Training Complete\n",
            "Fold 3 Accuracy: 0.5481\n",
            "\n",
            "Training On Fold 4\n",
            "Using Best Parameters From Fold 1: {'metric': 'manhattan', 'n_neighbors': 3, 'weights': 'distance'}\n",
            "Training KNN Model\n",
            "KNN Training Complete\n",
            "Fold 4 Accuracy: 0.5162\n",
            "\n",
            "Training On Fold 5\n",
            "Using Best Parameters From Fold 1: {'metric': 'manhattan', 'n_neighbors': 3, 'weights': 'distance'}\n",
            "Training KNN Model\n",
            "KNN Training Complete\n",
            "Fold 5 Accuracy: 0.6079\n",
            "\n",
            "Training On Fold 6\n",
            "Using Best Parameters From Fold 1: {'metric': 'manhattan', 'n_neighbors': 3, 'weights': 'distance'}\n",
            "Training KNN Model\n",
            "KNN Training Complete\n",
            "Fold 6 Accuracy: 0.5784\n",
            "\n",
            "Training On Fold 7\n",
            "Using Best Parameters From Fold 1: {'metric': 'manhattan', 'n_neighbors': 3, 'weights': 'distance'}\n",
            "Training KNN Model\n",
            "KNN Training Complete\n",
            "Fold 7 Accuracy: 0.5107\n",
            "\n",
            "Training On Fold 8\n",
            "Using Best Parameters From Fold 1: {'metric': 'manhattan', 'n_neighbors': 3, 'weights': 'distance'}\n",
            "Training KNN Model\n",
            "KNN Training Complete\n",
            "Fold 8 Accuracy: 0.5199\n",
            "\n",
            "Training On Fold 9\n",
            "Using Best Parameters From Fold 1: {'metric': 'manhattan', 'n_neighbors': 3, 'weights': 'distance'}\n",
            "Training KNN Model\n",
            "KNN Training Complete\n",
            "Fold 9 Accuracy: 0.5980\n",
            "\n",
            "Training On Fold 10\n",
            "Using Best Parameters From Fold 1: {'metric': 'manhattan', 'n_neighbors': 3, 'weights': 'distance'}\n",
            "Training KNN Model\n",
            "KNN Training Complete\n",
            "Fold 10 Accuracy: 0.5938\n",
            "\n",
            "Average Results Across 10 Folds For KNN\n",
            "Accuracy: 0.5599 (+/- 0.0346)\n",
            "Precision: 0.5799 (+/- 0.0452)\n",
            "Recall: 0.5599 (+/- 0.0346)\n",
            "F1 Score: 0.5481 (+/- 0.0390)\n",
            "MCC: 0.5123 (+/- 0.0391)\n",
            "ROC AUC: 0.8148 (+/- 0.0184)\n"
          ]
        }
      ],
      "source": [
        "    # 3. KNN\n",
        "    print('MODEL 3: KNN')\n",
        "    knn_fold_metrics, knn_avg_metrics = cross_validate_traditional_ml(\n",
        "        KNNModel, metadata, feature_extractor, urbansound8k,\n",
        "        model_name='KNN', hyperparameter_tuning=True\n",
        "    )\n",
        "    results['KNN'] = {'fold_metrics': knn_fold_metrics, 'avg_metrics': knn_avg_metrics}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X5cUhzDUogkm",
        "outputId": "012fa3fd-c417-499f-d9e8-b647966e642b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MODEL 4: ANN\n",
            "\n",
            "Starting 10 Fold Cross Validation For ANN\n",
            "Loading Cached Features From feature_cache/mfcc_stats_features.pkl\n",
            "\n",
            "Training On Fold 1\n",
            "Training ANN Model\n",
            "Epoch [10/50], Loss: 0.1636\n",
            "Epoch [20/50], Loss: 0.0982\n",
            "Epoch [30/50], Loss: 0.0737\n",
            "Epoch [40/50], Loss: 0.0380\n",
            "Epoch [50/50], Loss: 0.0499\n",
            "ANN Training Complete\n",
            "Fold 1 Accuracy: 0.6518\n",
            "\n",
            "Training On Fold 2\n",
            "Training ANN Model\n",
            "Epoch [10/50], Loss: 0.1691\n",
            "Epoch [20/50], Loss: 0.0881\n",
            "Epoch [30/50], Loss: 0.0623\n",
            "Epoch [40/50], Loss: 0.0528\n",
            "Epoch [50/50], Loss: 0.0199\n",
            "ANN Training Complete\n",
            "Fold 2 Accuracy: 0.6667\n",
            "\n",
            "Training On Fold 3\n",
            "Training ANN Model\n",
            "Epoch [10/50], Loss: 0.1689\n",
            "Epoch [20/50], Loss: 0.0874\n",
            "Epoch [30/50], Loss: 0.0659\n",
            "Epoch [40/50], Loss: 0.0520\n",
            "Epoch [50/50], Loss: 0.0186\n",
            "ANN Training Complete\n",
            "Fold 3 Accuracy: 0.6151\n",
            "\n",
            "Training On Fold 4\n",
            "Training ANN Model\n",
            "Epoch [10/50], Loss: 0.1845\n",
            "Epoch [20/50], Loss: 0.0857\n",
            "Epoch [30/50], Loss: 0.0686\n",
            "Epoch [40/50], Loss: 0.0493\n",
            "Epoch [50/50], Loss: 0.0170\n",
            "ANN Training Complete\n",
            "Fold 4 Accuracy: 0.6586\n",
            "\n",
            "Training On Fold 5\n",
            "Training ANN Model\n",
            "Epoch [10/50], Loss: 0.1826\n",
            "Epoch [20/50], Loss: 0.0922\n",
            "Epoch [30/50], Loss: 0.0728\n",
            "Epoch [40/50], Loss: 0.0596\n",
            "Epoch [50/50], Loss: 0.0419\n",
            "ANN Training Complete\n",
            "Fold 5 Accuracy: 0.7564\n",
            "\n",
            "Training On Fold 6\n",
            "Training ANN Model\n",
            "Epoch [10/50], Loss: 0.1756\n",
            "Epoch [20/50], Loss: 0.0937\n",
            "Epoch [30/50], Loss: 0.0571\n",
            "Epoch [40/50], Loss: 0.0393\n",
            "Epoch [50/50], Loss: 0.0432\n",
            "ANN Training Complete\n",
            "Fold 6 Accuracy: 0.6744\n",
            "\n",
            "Training On Fold 7\n",
            "Training ANN Model\n",
            "Epoch [10/50], Loss: 0.1700\n",
            "Epoch [20/50], Loss: 0.0940\n",
            "Epoch [30/50], Loss: 0.0571\n",
            "Epoch [40/50], Loss: 0.0280\n",
            "Epoch [50/50], Loss: 0.0252\n",
            "ANN Training Complete\n",
            "Fold 7 Accuracy: 0.7172\n",
            "\n",
            "Training On Fold 8\n",
            "Training ANN Model\n",
            "Epoch [10/50], Loss: 0.1808\n",
            "Epoch [20/50], Loss: 0.0916\n",
            "Epoch [30/50], Loss: 0.0705\n",
            "Epoch [40/50], Loss: 0.0486\n",
            "Epoch [50/50], Loss: 0.0215\n",
            "ANN Training Complete\n",
            "Fold 8 Accuracy: 0.6675\n",
            "\n",
            "Training On Fold 9\n",
            "Training ANN Model\n",
            "Epoch [10/50], Loss: 0.1780\n",
            "Epoch [20/50], Loss: 0.0959\n",
            "Epoch [30/50], Loss: 0.0622\n",
            "Epoch [40/50], Loss: 0.0471\n",
            "Epoch [50/50], Loss: 0.0382\n",
            "ANN Training Complete\n",
            "Fold 9 Accuracy: 0.7255\n",
            "\n",
            "Training On Fold 10\n",
            "Training ANN Model\n",
            "Epoch [10/50], Loss: 0.1965\n",
            "Epoch [20/50], Loss: 0.1007\n",
            "Epoch [30/50], Loss: 0.0756\n",
            "Epoch [40/50], Loss: 0.0288\n",
            "Epoch [50/50], Loss: 0.0411\n",
            "ANN Training Complete\n",
            "Fold 10 Accuracy: 0.7539\n",
            "\n",
            "Average Results Across 10 Folds For ANN\n",
            "Accuracy: 0.6887 (+/- 0.0445)\n",
            "Precision: 0.6873 (+/- 0.0491)\n",
            "Recall: 0.6887 (+/- 0.0445)\n",
            "F1 Score: 0.6781 (+/- 0.0482)\n",
            "MCC: 0.6533 (+/- 0.0495)\n",
            "ROC AUC: 0.9405 (+/- 0.0165)\n"
          ]
        }
      ],
      "source": [
        "    # 4. ANN\n",
        "    print('MODEL 4: ANN')\n",
        "    ann_fold_metrics, ann_avg_metrics = cross_validate_ann(\n",
        "        metadata, feature_extractor, urbansound8k,\n",
        "        model_name='ANN', epochs=50\n",
        "    )\n",
        "    results['ANN'] = {'fold_metrics': ann_fold_metrics, 'avg_metrics': ann_avg_metrics}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yyRLjRrVoiXx",
        "outputId": "61020491-08d8-4156-f095-73db7d55a22d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MODEL 5: 2D CNN\n",
            "\n",
            "Starting Fast Cross Validation For 2D CNN\n",
            "\n",
            "Training On Fold 1 (Fast Mode)\n",
            "Fold 1 Accuracy: 0.7342\n",
            "\n",
            "Training On Fold 2 (Fast Mode)\n",
            "Fold 2 Accuracy: 0.7759\n",
            "\n",
            "Training On Fold 3 (Fast Mode)\n",
            "Fold 3 Accuracy: 0.7081\n",
            "\n",
            "Training On Fold 4 (Fast Mode)\n",
            "Fold 4 Accuracy: 0.7859\n",
            "\n",
            "Training On Fold 5 (Fast Mode)\n",
            "Fold 5 Accuracy: 0.7543\n",
            "\n",
            "Training On Fold 6 (Fast Mode)\n",
            "Fold 6 Accuracy: 0.7521\n",
            "\n",
            "Training On Fold 7 (Fast Mode)\n",
            "Fold 7 Accuracy: 0.7100\n",
            "\n",
            "Training On Fold 8 (Fast Mode)\n",
            "Fold 8 Accuracy: 0.7134\n",
            "\n",
            "Training On Fold 9 (Fast Mode)\n",
            "Fold 9 Accuracy: 0.7868\n",
            "\n",
            "Training On Fold 10 (Fast Mode)\n",
            "Fold 10 Accuracy: 0.7431\n",
            "\n",
            "Average Results Across 10 Folds For 2D CNN\n",
            "Accuracy: 0.7464 (+/- 0.0286)\n",
            "Precision: 0.7698 (+/- 0.0258)\n",
            "Recall: 0.7464 (+/- 0.0286)\n",
            "F1 Score: 0.7401 (+/- 0.0321)\n",
            "MCC: 0.7200 (+/- 0.0302)\n",
            "ROC AUC: 0.9558 (+/- 0.0170)\n",
            "MODEL 6: 1D CNN\n",
            "\n",
            "Starting Fast Cross Validation For 1D CNN\n",
            "\n",
            "Training On Fold 1 (Fast Mode)\n",
            "Fold 1 Accuracy: 0.5842\n",
            "\n",
            "Training On Fold 2 (Fast Mode)\n",
            "Fold 2 Accuracy: 0.6205\n",
            "\n",
            "Training On Fold 3 (Fast Mode)\n",
            "Fold 3 Accuracy: 0.5427\n",
            "\n",
            "Training On Fold 4 (Fast Mode)\n",
            "Fold 4 Accuracy: 0.6081\n",
            "\n",
            "Training On Fold 5 (Fast Mode)\n",
            "Fold 5 Accuracy: 0.6816\n",
            "\n",
            "Training On Fold 6 (Fast Mode)\n",
            "Fold 6 Accuracy: 0.6525\n",
            "\n",
            "Training On Fold 7 (Fast Mode)\n",
            "Fold 7 Accuracy: 0.5907\n",
            "\n",
            "Training On Fold 8 (Fast Mode)\n",
            "Fold 8 Accuracy: 0.6799\n",
            "\n",
            "Training On Fold 9 (Fast Mode)\n",
            "Fold 9 Accuracy: 0.6630\n",
            "\n",
            "Training On Fold 10 (Fast Mode)\n",
            "Fold 10 Accuracy: 0.6523\n",
            "\n",
            "Average Results Across 10 Folds For 1D CNN\n",
            "Accuracy: 0.6275 (+/- 0.0436)\n",
            "Precision: 0.6368 (+/- 0.0420)\n",
            "Recall: 0.6275 (+/- 0.0436)\n",
            "F1 Score: 0.6156 (+/- 0.0466)\n",
            "MCC: 0.5865 (+/- 0.0477)\n",
            "ROC AUC: 0.8946 (+/- 0.0296)\n"
          ]
        }
      ],
      "source": [
        "    # 5. 2D CNN\n",
        "    print('MODEL 5: 2D CNN')\n",
        "    cnn2d_fold_metrics, cnn2d_avg_metrics = cross_validate_cnn2d(\n",
        "        metadata,\n",
        "        X_mel,   # Pass the pre-computed Mel Specs\n",
        "        y_mel,   # Pass the labels\n",
        "        model_name='2D CNN',\n",
        "        epochs=50,\n",
        "        batch_size=32\n",
        "    )\n",
        "    results['2D CNN'] = {'fold_metrics': cnn2d_fold_metrics, 'avg_metrics': cnn2d_avg_metrics}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "StUnJag60YGS",
        "outputId": "076fe58f-ea8c-445a-d2a6-d131c1286cb4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1. Encoding labels and moving data to GPU...\n",
            "Success! Data is on cuda.\n",
            "Features: torch.Size([8732, 1, 128, 345])\n",
            "Labels:   torch.Size([8732])\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "print(\"1. Encoding labels and moving data to GPU...\")\n",
        "\n",
        "# A. Convert String Labels to Integers\n",
        "le = LabelEncoder()\n",
        "y_mel_encoded = le.fit_transform(y_mel)\n",
        "\n",
        "# B. Move to GPU\n",
        "# Now we pass the integer-encoded labels instead of the strings\n",
        "X_mel_tensor = torch.FloatTensor(X_mel).to(device)\n",
        "y_mel_tensor = torch.LongTensor(y_mel_encoded).to(device)\n",
        "\n",
        "# Add channel dimension if needed (N, 1, H, W)\n",
        "if X_mel_tensor.ndim == 3:\n",
        "    X_mel_tensor = X_mel_tensor.unsqueeze(1)\n",
        "\n",
        "print(f\"Success! Data is on {device}.\")\n",
        "print(f\"Features: {X_mel_tensor.shape}\")\n",
        "print(f\"Labels:   {y_mel_tensor.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hd6scNZK52eE",
        "outputId": "d9e6d9a2-6a2a-433e-b659-12485b59183a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MODEL 10: SMART EFFICIENTNET + MIXUP\n",
            "\n",
            "Starting Smart Transfer + MixUp Run\n",
            "Fold 1... Acc: 0.7640\n",
            "Fold 2... Acc: 0.7590\n",
            "Fold 3... Acc: 0.7265\n",
            "Fold 4... Acc: 0.8374\n",
            "Fold 5... Acc: 0.8793\n",
            "Fold 6... Acc: 0.7959\n",
            "Fold 7... Acc: 0.8484\n",
            "Fold 8... Acc: 0.7568\n",
            "Fold 9... Acc: 0.8554\n",
            "Fold 10... Acc: 0.8160\n",
            "Accuracy: 0.8039 (+/- 0.0484)\n",
            "Precision: 0.8157 (+/- 0.0432)\n",
            "Recall: 0.8039 (+/- 0.0484)\n",
            "F1 Score: 0.7974 (+/- 0.0518)\n",
            "MCC: 0.7833 (+/- 0.0524)\n",
            "ROC AUC: 0.9679 (+/- 0.0141)\n"
          ]
        }
      ],
      "source": [
        "from torchvision.models import efficientnet_b0\n",
        "import torch.distributions.beta as beta\n",
        "\n",
        "# 1. Define the EfficientNet\n",
        "class SmartAudioEfficientNet(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(SmartAudioEfficientNet, self).__init__()\n",
        "\n",
        "        # Load Pre-trained\n",
        "        self.base_model = efficientnet_b0(weights='DEFAULT')\n",
        "\n",
        "       \n",
        "        # Instead of a random new layer, we copy the pre-trained weights.\n",
        "        # We average the 3 RGB channels into 1 Grayscale channel.\n",
        "        original_layer = self.base_model.features[0][0]\n",
        "        original_weights = original_layer.weight.data # Shape: [32, 3, 3, 3]\n",
        "\n",
        "        # Average across the channel dimension (dim=1)\n",
        "        new_weights = original_weights.mean(dim=1, keepdim=True) # Shape: [32, 1, 3, 3]\n",
        "\n",
        "        # Create new layer\n",
        "        self.base_model.features[0][0] = nn.Conv2d(\n",
        "            in_channels=1,\n",
        "            out_channels=original_layer.out_channels,\n",
        "            kernel_size=original_layer.kernel_size,\n",
        "            stride=original_layer.stride,\n",
        "            padding=original_layer.padding,\n",
        "            bias=False\n",
        "        )\n",
        "\n",
        "        # Load the averaged weights into the new layer\n",
        "        self.base_model.features[0][0].weight.data = new_weights\n",
        "\n",
        "        # Modify Output\n",
        "        in_features = self.base_model.classifier[1].in_features\n",
        "        self.base_model.classifier[1] = nn.Sequential(\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(in_features, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.base_model(x)\n",
        "\n",
        "# 2. MixUp Function (The Secret Sauce)\n",
        "def mixup_data(x, y, alpha=0.2):\n",
        "    '''Returns mixed inputs, pairs of targets, and lambda'''\n",
        "    if alpha > 0:\n",
        "        lam = np.random.beta(alpha, alpha)\n",
        "    else:\n",
        "        lam = 1\n",
        "\n",
        "    batch_size = x.size()[0]\n",
        "    index = torch.randperm(batch_size).to(device)\n",
        "\n",
        "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
        "    y_a, y_b = y, y[index]\n",
        "    return mixed_x, y_a, y_b, lam\n",
        "\n",
        "def mixup_criterion(criterion, pred, y_a, y_b, lam):\n",
        "    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)\n",
        "\n",
        "# 3. The New Training Loop\n",
        "def cross_validate_smart_mixup(metadata, X_gpu, y_gpu, epochs=20, batch_size=64):\n",
        "    print(f'\\nStarting Smart Transfer + MixUp Run')\n",
        "\n",
        "    label_encoder = LabelEncoder()\n",
        "    label_encoder.fit(metadata['class'])\n",
        "    class_names = label_encoder.classes_\n",
        "    evaluator = ModelEvaluator(class_names)\n",
        "    scaler = GradScaler()\n",
        "    fold_metrics = []\n",
        "\n",
        "    for fold in range(1, 11):\n",
        "        print(f'Fold {fold}...', end=' ')\n",
        "\n",
        "        train_idx = torch.tensor(metadata[metadata['fold'] != fold].index.values).to(device)\n",
        "        test_idx = torch.tensor(metadata[metadata['fold'] == fold].index.values).to(device)\n",
        "\n",
        "        X_train, y_train = X_gpu[train_idx], y_gpu[train_idx]\n",
        "        X_test, y_test = X_gpu[test_idx], y_gpu[test_idx]\n",
        "\n",
        "        model = SmartAudioEfficientNet(num_classes=len(class_names)).to(device)\n",
        "\n",
        "        # Slightly higher LR because we are using MixUp (harder task)\n",
        "        optimizer = optim.Adam(model.parameters(), lr=3e-4)\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "        model.train()\n",
        "        num_samples = X_train.shape[0]\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            perm = torch.randperm(num_samples, device=device)\n",
        "            for i in range(0, num_samples, batch_size):\n",
        "                indices = perm[i : i + batch_size]\n",
        "                batch_X = X_train[indices]\n",
        "                batch_y = y_train[indices]\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "                with autocast():\n",
        "                    # Apply MixUp\n",
        "                    inputs, targets_a, targets_b, lam = mixup_data(batch_X, batch_y)\n",
        "                    outputs = model(inputs)\n",
        "                    loss = mixup_criterion(criterion, outputs, targets_a, targets_b, lam)\n",
        "\n",
        "                scaler.scale(loss).backward()\n",
        "                scaler.step(optimizer)\n",
        "                scaler.update()\n",
        "\n",
        "        # Evaluation (No MixUp here)\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            y_pred = []\n",
        "            y_proba = []\n",
        "\n",
        "            for i in range(0, X_test.shape[0], batch_size):\n",
        "                batch_X = X_test[i : i + batch_size]\n",
        "                outputs = model(batch_X)\n",
        "                probs = F.softmax(outputs, dim=1)\n",
        "                preds = torch.max(probs, 1)[1]\n",
        "                y_pred.extend(preds.cpu().numpy())\n",
        "                y_proba.extend(probs.cpu().numpy())\n",
        "\n",
        "            y_test_cpu = y_test.cpu().numpy()\n",
        "\n",
        "        metrics = evaluator.compute_metrics(np.array(y_test_cpu), np.array(y_pred), np.array(y_proba))\n",
        "        fold_metrics.append(metrics)\n",
        "        print(f\"Acc: {metrics['accuracy']:.4f}\")\n",
        "\n",
        "    avg_metrics = aggregate_metrics(fold_metrics)\n",
        "    print_average_metrics(avg_metrics)\n",
        "    return fold_metrics, avg_metrics\n",
        "\n",
        "# --- EXECUTION ---\n",
        "print('MODEL 10: SMART EFFICIENTNET + MIXUP')\n",
        "\n",
        "smart_fold_metrics, smart_avg_metrics = cross_validate_smart_mixup(\n",
        "    metadata,\n",
        "    X_mel_tensor,\n",
        "    y_mel_tensor,\n",
        "    epochs=25,     # Increased slightly for MixUp\n",
        "    batch_size=64\n",
        ")\n",
        "\n",
        "results['Smart_EfficientNet'] = {'fold_metrics': smart_fold_metrics, 'avg_metrics': smart_avg_metrics}"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
